<!doctype html>
<html>

<head>
  <title>MMM2024</title>
  <meta charset="utf-8" name="viewport" content="width=device-width, initial-scale=1">
  <link href="https://use.fontawesome.com/releases/v5.2.0/css/all.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/frame.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/controls.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/custom.css" media="screen" rel="stylesheet" type="text/css" />
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Open+Sans+Condensed:300,700' rel='stylesheet' type='text/css'>
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700" rel="stylesheet">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script src="js/menu.js"></script>
  <script src="js/footer.js"></script>
  <style>
    .menu-submit {
      color: rgb(0, 0, 0) !important;
      opacity: 1 !important;
      font-weight: 700 !important;
    }
  </style>
</head>

<body>
  <div class="menu-container"></div>
  <div class="content-container">
    <div class="banner" style="background: url('img/feature.jpeg') no-repeat center; background-size: cover; height: 450px;">
      <div class="banner-table flex-column" style="background-color: rgba(0, 0, 0, 0.5);">
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin-small">Call for Submissions</h2>
          </div>
        </div>
      </div>
    </div>
    <div class="content" id="dates">
      <div class="content-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column full-width">
            <h2 class="add-top-margin-small">Important Dates</h2>
            <hr>
            <ul>
              <li>Regular and Special Session Paper Submission: <b>4 September 2023</b></li>
              <li>Demo Paper Submission: <b>2 October 2023</b></li>
              <li>Brave New Ideas Submission: <b>2 October 2023</b></li>
              <li>Video Browser Showdown Submission: <b>16 October 2023</b></li>
              <li>Regular and Special Session Paper Notification: <b>13 November 2023</b></li>
              <li>Camera Ready Version and Registration: <b>4 December 2023</b></li>
            </ul>
            <p class="text">
              All deadlines refer to midnight in the GMT-11 time zone.
              This is Conftool's best available approximation of "Anywhere on Earth", and could be called "Anywhere on Inhabited Earth", see <a href="https://www.conftool.net/ctforum/index.php/topic,447.0.html">this website page</a>.
              The Conftool system will accurately indicate the time in GMT-11.
            </p>
          </div>
        </div>
      </div>
    </div>
    <div class="banner" id="toi">
      <div class="banner-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin-small">Topics of Interest</h2>
          </div>
        </div>
      </div>
    </div>
    <div class="content">
      <div class="content-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column full-width">
            <h2 class="add-top-margin-small">Multimedia Content Analysis</h2>
            <hr>
            <ul>
              <li>Multimedia indexing</li>
              <li>Multimedia mining</li>
              <li>Multimedia abstraction and summarisation</li>
              <li>Multimedia annotation, tagging and recommendation</li>
              <li>Multimodal analysis for retrieval applications</li>
              <li>Semantic analysis of multimedia and contextual data</li>
              <li>Interactive learning</li>
              <li>Multimedia knowledge acquisition and construction</li>
              <li>Multimedia verification</li>
              <li>Multimedia fusion methods</li>
              <li>Multimedia content generation</li>
            </ul>

            <h2 class="add-top-margin-small">Multimedia Signal Processing and Communications</h2>
            <hr>
            <ul>
              <li>Media representation and algorithms</li>
              <li>Multimedia sensors and interaction modes</li>
              <li>Multimedia privacy, security and content protection</li>
              <li>Multimedia standards and related issues</li>
              <li>Multimedia databases, query processing, and scalability</li>
              <li>Multimedia content delivery, transport and streaming</li>
              <li>Wireless and mobile multimedia networking</li>
              <li>Sensor networks (video surveillance, distributed systems)</li>
              <li>Audio, image, video processing, coding and compression</li>
              <li>Multi-camera and multi-view systems</li>
            </ul>

            <h2 class="add-top-margin-small">Multimedia Applications, Interfaces and Services</h2>
            <hr>
            <ul>
              <li>Media content retrieval, browsing and recommendation tools</li>
              <li>Extended reality (AR/VR/MR) and virtual environments</li>
              <li>Real-time and interactive multimedia applications</li>
              <li>Multimedia analytics applications</li>
              <li>Egocentric, wearable and personal multimedia</li>
              <li>Urban and satellite multimedia</li>
              <li>Mobile multimedia applications</li>
              <li>Question answering, multimodal conversational AI and hybrid intelligence</li>
              <li>Multimedia authoring and personalisation</li>
              <li>Cultural, educational and social multimedia applications</li>
              <li>Multimedia for e-health and medical applications</li>
            </ul>

            <h2 class="add-top-margin-small">Ethical, Legal and Societal Aspects of Multimedia</h2>
            <hr>
            <ul>
              <li>Fairness, accountability, transparency and ethics in multimedia modeling</li>
              <li>Environmental footprint of multimedia modeling</li>
              <li>Large multimedia models and LLMs</li>
              <li>Multimodal pretraining and representation learning</li>
              <li>Reproducibility, interpretability, explainability and robustness </li>
              <li>Embodied multimodal applications and tasks</li>
              <li>Responsible multimedia modeling and learning</li>
              <li>Legal and ethical aspects of multimodal generative AI</li>
              <li>Multimedia research valorisation</li>
              <li>Digital transformation</li>
            </ul>
          </div>
        </div>
      </div>
    </div>
    <div class="banner" id="regular">
      <div class="banner-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin-small">Regular Papers</h2>
          </div>
        </div>
      </div>
    </div>
    <div class="content">
      <div class="content-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column full-width">
            <p class="text">
              MMM is a leading international conference for researchers and industry practitioners for sharing new ideas, original research results and practical development experiences from all MMM related areas.
              The conference calls for research papers reporting original investigation results and demonstrations reporting novel and compelling applications.
            </p>
            <p class="text">
              The proceedings of previous editions of MMM can be found <a href="https://link.springer.com/conference/mmm">here</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
    <div class="banner" id="demo">
      <div class="banner-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin-small">Demo Papers</h2>
          </div>
        </div>
      </div>
    </div>
    <div class="content">
      <div class="content-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column full-width">
            <p class="text">
              Description of demo papers will be here.
            </p>
          </div>
        </div>
      </div>
    </div>
    <div class="banner" id="brave">
      <div class="banner-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin-small">Brave New Ideas</h2>
          </div>
        </div>
      </div>
    </div>
    <div class="content">
      <div class="content-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column full-width">
            <p class="text">
              The Brave New Ideas track of MMM 2024 is calling for papers that suggest
              new opportunities and challenges in the general domain of multimedia
              analytics and modelling. A BNI paper is expected to stimulate activity
              towards addressing new, long term challenges of interest to the
              multimedia modelling community. The papers should address topics with a
              clear potential for high societal impact; authors should be able to
              argue that their proposal is important to solving problems, to
              supporting new perspectives, or to providing services that positively
              impact on people. Note that is not necessary that papers in this track
              have large-scale experimental results or comparisons to the state of the
              art, since it is expected that large, publicly available datasets may
              not be available, and there may be no existing approaches to which the
              proposed approach in the paper can be compared. BNI papers should adhere
              to the same formatting guidelines and page limits as the Regular and
              Special Session papers.
            </p>
          </div>
        </div>
      </div>
    </div>
    <div class="banner" id="special">
      <div class="banner-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin-small">Special Session Papers</h2>
          </div>
        </div>
      </div>
    </div>
    <div class="content">
      <div class="content-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column full-width">
            <p class="text">
              Special session papers must follow <a href="guidelines.html">the same guidelines</a> as regular research papers with respect to restrictions on formatting, length, and double-blind reviews.
              Only MDRE papers will undergo single-blind review, and authors will not have to anonymize their MDRE papers because of the inherent difficulty of doing so for open datasets.
            </p>
            <ul>
              <li>
                <a href="specialpaper.html#s1">MDRE: Multimedia Datasets for Repeatable Experimentation.</a>
                This special session focuses on sharing data and code to allow other researchers to replicate research results, with a long term goal of improving the performance of systems and the reproducibility of published papers.
              </li>
              <li>
                <a href="specialpaper.html#s2">MOMST: Multi-Object Multi-Sensor Tracking.</a>
                This special session addresses the challenging problem of multi-object multi-sensor tracking in computer vision and machine learning, essential in applications such as surveillance systems, autonomous vehicles, and robotics.
              </li>
              <li>
                <a href="specialpaper.html#s3">MARGeM: Multimodal Analytics and Retrieval of Georeferenced Multimedia.</a>
                This special session focuses on multimodal analytics and retrieval techniques for georeferenced multimedia data, addressing challenges in lifelog computing, urban computing, satellite computing, and earth observation
              </li>
              <li>
                <a href="specialpaper.html#s4">ICDAR: Intelligent Cross-Data Analysis and Retrieval.</a>
                This special session focuses on intelligent cross-data analytics and retrieval research and to bring a smart, sustainable society to human beings.
              </li>
              <li>
                <a href="specialpaper.html#s5">XR-MACCI: eXtended Reality and Multimedia - Advancing Content Creation and Interaction.</a>
                This Special session focuses on the latest advancements in extended reality (XR) and multimedia technologies, including the development and integration of XR solutions with multimedia analysis, retrieval and processing methods.
              </li>
              <li>
                <a href="specialpaper.html#s6">FMM: Foundation Models for Multimedia.</a>
                This special session focuses on the transformative impact of Foundation Models (FMs) such as large language models (LLMs) and large vision language models (LVLMs) and explores the future directions and challenges in harnessing FMs for multimedia applications.
              </li>
              <li>
                <a href="specialpaper.html#s7">MULTICON: Towards Multimedia and Multimodality in Conversational Systems.</a>
                This special session aims to present the most recent works and applications for addressing the challenges and opportunities in developing multimedia and multimodality-enabled conversational systems and chatbots. Indicative domains of application include healthcare, education, immigration, customer service, finance and others.
              </li>
              <li>
                <a href="specialpaper.html#s8">CultMM: Cultural AI in Multimedia.</a>
                This Special session aims to bring together experts from Cultural AI and Multimedia to discuss the challenges surrounding cultural data, as well as the complexities of human culture, that require multimedia solutions.
              </li>
            </ul>
          </div>
        </div>
      </div>
    </div>
    <div class="footer-container"></div>
</body>

</html>