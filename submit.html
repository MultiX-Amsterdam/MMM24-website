<!doctype html>
<html>

<head>
  <title>MMM2024 - Submit</title>
  <meta charset="utf-8" name="viewport" content="width=device-width, initial-scale=1">
  <link href="https://use.fontawesome.com/releases/v5.2.0/css/all.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/frame.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/controls.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/custom.css" media="screen" rel="stylesheet" type="text/css" />
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Open+Sans+Condensed:300,700' rel='stylesheet' type='text/css'>
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700" rel="stylesheet">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script src="js/menu.js"></script>
  <script src="js/footer.js"></script>
  <style>
    .menu-submit {
      color: rgb(255, 255, 255) !important;
      opacity: 1 !important;
      font-weight: 700 !important;
    }
  </style>
</head>

<body>
  <div class="menu-container"></div>
  <div class="content-container">
    <div class="banner" style="background: url('img/feature.jpeg') no-repeat center; background-size: cover; height: 450px;">
      <div class="banner-table flex-column" style="background-color: rgba(0, 0, 0, 0.5);">
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin-small">Call for Submissions</h2>
          </div>
        </div>
      </div>
    </div>
    <div class="content" id="dates">
      <div class="content-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column full-width">
            <h2>Important Dates</h2>
            <hr>
            <ul>
            <ul>
              <li>Regular and Special Session Paper Submission: 4 September 2023</li>
              <li>Regular and Special Session Paper Notification: 13 November 2023</li>
              <li>Camera Ready Version and Registration: 4 December 2023</li>
            </ul>
          </div>
        </div>
      </div>
    </div>
    <div class="banner" id="toi">
      <div class="banner-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin-small">Topics of Interest</h2>
          </div>
        </div>
      </div>
    </div>
    <div class="content">
      <div class="content-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column full-width">
            <h2 class="add-top-margin-small">Multimedia Content Analysis</h2>
            <hr>
            <ul>
              <li>Multimedia indexing</li>
              <li>Multimedia mining</li>
              <li>Multimedia abstraction and summarisation</li>
              <li>Multimedia annotation, tagging and recommendation</li>
              <li>Multimodal analysis for retrieval applications</li>
              <li>Semantic analysis of multimedia and contextual data</li>
              <li>Interactive learning</li>
              <li>Multimedia knowledge acquisition and construction</li>
              <li>Multimedia verification</li>
              <li>Multimedia fusion methods</li>
              <li>Multimedia content generation</li>
            </ul>

            <h2 class="add-top-margin-small">Multimedia Signal Processing and Communications</h2>
            <hr>
            <ul>
              <li>Media representation and algorithms</li>
              <li>Multimedia sensors and interaction modes</li>
              <li>Multimedia privacy, security and content protection</li>
              <li>Multimedia standards and related issues</li>
              <li>Multimedia databases, query processing, and scalability</li>
              <li>Multimedia content delivery, transport and streaming</li>
              <li>Wireless and mobile multimedia networking</li>
              <li>Sensor networks (video surveillance, distributed systems)</li>
              <li>Audio, image, video processing, coding and compression</li>
              <li>Multi-camera and multi-view systems</li>
            </ul>

            <h2 class="add-top-margin-small">Multimedia Applications, Interfaces and Services</h2>
            <hr>
            <ul>
              <li>Media content retrieval, browsing and recommendation tools</li>
              <li>Extended reality (AR/VR/MR) and virtual environments</li>
              <li>Real-time and interactive multimedia applications</li>
              <li>Multimedia analytics applications</li>
              <li>Egocentric, wearable and personal multimedia</li>
              <li>Urban and satellite multimedia</li>
              <li>Mobile multimedia applications</li>
              <li>Question answering, multimodal conversational AI and hybrid intelligence</li>
              <li>Multimedia authoring and personalisation</li>
              <li>Cultural, educational and social multimedia applications</li>
              <li>Multimedia for e-health and medical applications</li>
            </ul>

            <h2 class="add-top-margin-small">Ethical, Legal and Societal Aspects of Multimedia</h2>
            <hr>
            <ul>
              <li>Fairness, accountability, transparency and ethics in multimedia modeling</li>
              <li>Environmental footprint of multimedia modeling</li>
              <li>Large multimedia models and LLMs</li>
              <li>Multimodal pretraining and representation learning</li>
              <li>Reproducibility, interpretability, explainability and robustness </li>
              <li>Embodied multimodal applications and tasks</li>
              <li>Responsible multimedia modeling and learning</li>
              <li>Legal and ethical aspects of multimodal generative AI</li>
              <li>Multimedia research valorisation</li>
              <li>Digital transformation</li>
            </ul>
          </div>
        </div>
      </div>
    </div>
    <div class="banner" id="regular">
      <div class="banner-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin-small">Regular Papers</h2>
          </div>
        </div>
      </div>
    </div>
    <div class="content">
      <div class="content-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column full-width">
            <p class="text">
              MMM is a leading international conference for researchers and industry practitioners for sharing new ideas, original research results and practical development experiences from all MMM related areas. The conference calls for research papers reporting original investigation results and demonstrations reporting novel and compelling applications. </p>

            <p class="text">
              The proceedings of of previous editions of MMM can be found <a href="https://link.springer.com/conference/mmm">here</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
    <div class="banner" id="demo">
      <div class="banner-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin-small">Demo Papers</h2>
          </div>
        </div>
      </div>
    </div>
    <div class="content">
      <div class="content-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column full-width">
            <p class="text">
              Description of demo papers will be here.
            </p>
          </div>
        </div>
      </div>
    </div>
    <div class="banner" id="special">
      <div class="banner-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin-small">Special Session Papers</h2>
          </div>
        </div>
      </div>
    </div>
    <div class="content">
      <div class="content-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column full-width">
            <p class="text">
              Special session papers must follow <a href="guidelines.html">the same guidelines</a> as regular research papers with respect to restrictions on formatting, length, and double-blind reviews.
              Only MDRE papers will undergo single-blind review, and authors will not have to anonymize their MDRE papers because of the inherent difficulty of doing so for open datasets.
            </p>
            <ul>
              <li>
                <a href="specialpaper.html#s1">MDRE: Multimedia Datasets for Repeatable Experimentation.</a>
                This special session focuses on sharing data and code to allow other researchers to replicate research results, with a long term goal of improving the performance of systems and the reproducibility of published papers.
              </li>
              <li>
                <a href="specialpaper.html#s2">MOMST: Multi-Object Multi-Sensor Tracking.</a>
                This special session addresses the challenging problem of multi-object multi-sensor tracking in computer vision and machine learning, essential in applications such as surveillance systems, autonomous vehicles, and robotics.
              </li>
              <li>
                <a href="specialpaper.html#s3">MARGeM: Multimodal Analytics and Retrieval of Georeferenced Multimedia.</a>
                This special session focuses on multimodal analytics and retrieval techniques for georeferenced multimedia data, addressing challenges in lifelog computing, urban computing, satellite computing, and earth observation
              </li>
              <li>
                <a href="specialpaper.html#s4">ICDAR: Intelligent Cross-Data Analysis and Retrieval.</a>
                This special session focuses on intelligent cross-data analytics and retrieval research and to bring a smart, sustainable society to human beings.
              </li>
              <li>
                <a href="specialpaper.html#s5">XR-MACCI: eXtended Reality and Multimedia - Advancing Content Creation and Interaction.</a>
                This Special session focuses on the latest advancements in extended reality (XR) and multimedia technologies, including the development and integration of XR solutions with multimedia analysis, retrieval and processing methods.
              </li>
              <li>
                <a href="specialpaper.html#s6">FMM: Foundation Models for Multimedia.</a>
                This special session focuses on the transformative impact of Foundation Models (FMs) such as large language models (LLMs) and large vision language models (LVLMs) and explores the future directions and challenges in harnessing FMs for multimedia applications.
              </li>
              <li>
                <a href="specialpaper.html#s7">MULTICON: Towards Multimedia and Multimodality in Conversational Systems.</a>
                This special session aims to present the most recent works and applications for addressing the challenges and opportunities in developing multimedia and multimodality-enabled conversational systems and chatbots. Indicative domains of application include healthcare, education, immigration, customer service, finance and others.
              </li>
              <li>
                <a href="specialpaper.html#s8">CultMM: Cultural AI in Multimedia.</a>
                This Special session aims to bring together experts from Cultural AI and Multimedia to discuss the challenges surrounding cultural data, as well as the complexities of human culture, that require multimedia solutions.
              </li>
            </ul>
          </div>
        </div>
      </div>
    </div>
    <div class="footer-container"></div>
</body>

</html>
