<!doctype html>
<html>

<head>
  <title>MMM2024</title>
  <meta charset="utf-8" name="viewport" content="width=device-width, initial-scale=1">
  <link href="https://use.fontawesome.com/releases/v5.2.0/css/all.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/frame.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/controls.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/custom.css" media="screen" rel="stylesheet" type="text/css" />
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Open+Sans+Condensed:300,700' rel='stylesheet' type='text/css'>
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700" rel="stylesheet">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script src="js/menu.js"></script>
  <script src="js/footer.js"></script>
  <style>
    .menu-conference {
      color: rgb(0, 0, 0) !important;
      opacity: 1 !important;
      font-weight: 700 !important;
    }
  </style>
</head>

<body>
  <div class="menu-container"></div>
  <div class="content-container">
    <div class="banner" style="background: url('img/feature.jpeg') no-repeat center; background-size: cover; height: 450px;">
      <div class="banner-table flex-column" style="background-color: rgba(0, 0, 0, 0.5);">
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h1 class="add-top-margin-small">Conference</h1>
          </div>
        </div>
      </div>
    </div>
    <div class="banner" id="program">
      <div class="banner-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin-small">Conference Program</h2>
          </div>
        </div>
      </div>
    </div>
    <div class="content">
      <div class="content-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column">
            <div class="control-group">
              <a class="custom-button-flat large pulse-primary" href="file/mmm-2024-full-program.pdf" target="_blank">
                <img src="img/link.png"><span>Download Full Program</span>
              </a>
            </div>
            <p class="text">
              You can download the full program PDF by clicking on the above button.
            </p>
            <h3>Program Outline</h3>
            <hr>
            <p class="text">
              Below is the program outline.
            </p>
            <div class="scrollable-image-container center add-top-margin-small">
              <img class="scrollable-image center" style="max-width: 838px;" src="img/program_outline.png">
            </div>
          </div>
        </div>
      </div>
    </div>
    <div class="banner" id="proceedings">
      <div class="banner-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin-small">Conference Proceedings</h2>
          </div>
        </div>
      </div>
    </div>
    <div class="content">
      <div class="content-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column">
            <p class="text">
              The conference proceedings for MMMM2024 are available online at Springer:
            </p>
            <div class="control-group">
              <a class="custom-button-flat large" href="https://link.springer.com/book/10.1007/978-3-031-53305-1" target="_blank">
                <img src="img/link.png"><span>View Proceedings Part I</span>
              </a>
              <a class="custom-button-flat large" href="https://link.springer.com/book/10.1007/978-3-031-53308-2" target="_blank">
                <img src="img/link.png"><span>View Proceedings Part II</span>
              </a>
              <a class="custom-button-flat large" href="https://link.springer.com/book/10.1007/978-3-031-53311-2" target="_blank">
                <img src="img/link.png"><span>View Proceedings Part III</span>
              </a>
              <a class="custom-button-flat large" href="https://link.springer.com/book/10.1007/978-3-031-53302-0" target="_blank">
                <img src="img/link.png"><span>View Proceedings Part IV</span>
              </a>
            </div>
          </div>
        </div>
      </div>
    </div>
    <div class="banner" id="keynotes">
      <div class="banner-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin-small">Keynotes</h2>
          </div>
        </div>
      </div>
    </div>
    <div class="content">
      <div class="content-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h3 id="keynote-vilanova">Anna Vilanova &#8212; Visual Analytics: Machine Learning and the Human in the Loop</h3>
            <hr>
            <p class="text">
              <img class="image image-wrap-text-custom max-width-200" src="img/anna.jpg">Visual Analytics wants to foster the strengths of humans and computers effectively through the combination of automatic data analysis methods, visualization, and interaction. Visual analytics is an extension of machine learning methods. It is also a complement to the already existing visualization techniques by the introduction of the concepts of reasoning and machine learning. Machine learning has
              successfully developed models that outperform humans in several tasks. However, this success is limited when it comes to increasing knowledge, and providing new understanding based on new data. Humans uniquely understand the world through intuition, common sense, creativity, and emotion, capabilities that are required for many multi-faceted tasks. In this talk, I will present our work and my view on embedding the human in the loop in the machine learning context through the
              concepts of visual analytics. In particular, we focus on data exploration, and hypothesis generation relying on dimensionality reduction methods as an effective visual analytics component for large high-dimensional data. Furthermore, I will discuss the promise, challenges, and current research in visual analytics to open the black box of machine learning models.
            </p>
            <p class="text">
              <b>Prof. Dr. Anna Vilanova</b> is full professor in visual analytics (<a href="http://vis.win.tue.nl">vis.win.tue.nl</a>) since October 2019, at the department of Mathematics and Computer Science, at the Eindhoven University of Technology (TU/e). Previously she was associate professor for 6 years at the Computer Graphics & Visualization Group at EEMCS at the University of Delft, the Netherlands. From 2002 to August 2013, she was Assistant Professor at the Biomedical Image Analysis
              group of the Biomedical Engineering Department at TU/e. She is leading a research group in the subject of visual analytics and multivalued image analysis and visualization, focusing on visual analytics for high dimensional complex data and explainable AI. She focuses on Biomedical applications such as: Diffusion Weighted Imaging, 4D Flow and Pan-genomics. She was member of the steering committee of EuroVis (2014 -2018) and VCBM (2018-2022). She is elected member of the EUROGRAPHICS
              executive committee since 2015, vice president (2019-2022), and currently president of EUROGRAPHICS. She also became EUROGRAPHICS fellow in 2019. She is elected member of IEEE VIS Steering Committee (VSC) since 2021.
            </p>
          </div>
          <div class="flex-item flex-column">
            <h3 id="keynote-snoek">Cees Snoek &#8212; What Multimodal Foundation Models Cannot Perceive</h3>
            <hr>
            <p class="text">
              <img class="image image-wrap-text-custom max-width-200" src="img/cees.jpeg">
              Multimodal foundation models are a revolutionary class of AI models that provide impressive abilities to generate multimedia content and do so by interactive prompts in a seemingly creative manner.
              These foundation models are often self-supervised transformer-based models pre-trained on large volumes of data, typically collected from the web.
              They already form the basis of all state-of-the-art systems in computer vision and natural language processing across a wide range of tasks and have shown impressive transfer learning abilities.
              Despite their immense potential, these foundation models face challenges in fundamental perception tasks such as spatial grounding and temporal reasoning, have difficulty to operate on low-resource scenarios, and neglect human-alignment for ethical, legal, and societal acceptance.
              In this talk I will highlight recent work from my lab that identifies several of these challenges as well as ways to update foundation models to address these challenges and to do so in a sustainable way, without the need to retrain from scratch.
            </p>
            <p class="text">
              <b>Prof. Dr. Cees G.M. Snoek</b> is a full professor in computer science at the University of Amsterdam, where he heads the Video & Image Sense Lab. He is also a director of three public-private AI research labs: QUVA Lab with Qualcomm, Atlas Lab with TomTom and AIM Lab with the Inception Institute of Artificial Intelligence. At University spin-off Kepler Vision Technologies he acts as Chief Scientific Officer. Professor Snoek is also the director of the ELLIS Amsterdam Unit and
              scientific director of Amsterdam AI, a collaboration between government, academic, medical and other organisations in Amsterdam to help the city develop and deploy responsible AI.
              His research interests focus on making sense of video and images. He has published over 200 refereed book chapters, journal and conference papers, and frequently serves as an area chair of the major conferences in computer vision and multimedia. He is currently an associate editor for Computer Vision and Image Understanding and the IEEE Transactions on Pattern Analysis and Machine Intelligence.
            </p>
          </div>
          <div class="flex-item flex-column">
            <h3 id="keynote-zeldenrust">Fleur Zeldenrust &#8212; From Structure to Function: How Do Neural Properties Influence Information Transfer?</h3>
            <hr>
            <p class="text">
              <img class="image image-wrap-text-custom max-width-200" src="img/fleur.jpeg">
              The brain is a unique system, in that its dynamics have a clear
              function: making its owner respond to the world around it. In order to
              perform this function, the brain continuously processes information. How
              do the dynamics of neurons and networks result in information
              processing? The physical structure of the brain (its "hardware") shapes
              this information processing and vice versa: the computations needed for
              information processing (the "software") are adapted to the physical
              structure of the hardware. Here, I will discuss this relationship
              between information processing and neural properties on different
              levels, from single neurons to networks, and from different
              perspectives, from single cell electrophysiology to network modelling.
            </p>
            <p class="text">
              <b>Fleur Zeldenrust</b> started studying physics, but switched to neuroscience
              during her master's degree. She obtained a PhD in computational
              neuroscience in 2012, from the University of Amsterdam, supervised by
              Wytse Wadman. After performing postdoctoral research at the École
              Normale Supérieure in Paris with Boris Gutkin and Sophie Denève, she
              returned to the Netherlands to design a bachelour track in computational
              neuroscience in the Psychobiology BSc degree at the University of
              Amsterdam. An NWO Veni grant (2015) and later a Marie Curie Training
              Network grant (2019, 'SmartNets') allowed her to start her own research
              group at the Donders Institute for Brain, Cognition and Behaviour of the
              Radboud University in Nijmegen. She recently obtained an NWO Vidi grant
              to research the influence of neuromodulators on information processing
              in the brain. Next to her research, she is very passionate about
              communicating neuroscience to the public, (co-)founding amongst others
              the Dutch Brain Olympiad and the BrainHelpDesk.
            </p>
          </div>
          <div class="flex-item flex-column">
            <h3 id="keynote-kompatsiaris">Ioannis (Yiannis) Kompatsiaris &#8212; Visual and Multimodal Disinformation Detection</h3>
            <hr>
            <p class="text">
              <img class="image image-wrap-text-custom max-width-200" src="img/ioannis.jpeg">
              Recent technological developments (including Generative AI) and social media have contributed to a constant increase in online disinformation of various forms making it a long-lasting challenge of immense scale and complexity.
              The talk starts with an introduction on challenges and properties of online disinformation including the significant impact on key societal values such as Democracy, Public Health and Peace.
              Focusing on visual disinformation, manipulated photos/video, deepfakes and visuals out of context, a variety of approaches and tools are needed in order to address this challenge.
              The talk includes relevant approaches in this area, focusing on multimodal misinformation detection and multimodal fact-checking.
              Key additional aspects such as use cases (journalism, strengthening First Responders (FR)), policies, business models, education, digital literacy and human behaviour will also be covered.
            </p>
            <p class="text">
              <b>Dr. Ioannis (Yiannis) Kompatsiaris</b> is the Director of CERTH-ITI and the
              Head of Multimedia Knowledge and Social Media Analytics Laboratory. His
              research interests include AI/ML for Multimedia, Semantics (multimedia
              ontologies and reasoning), Social Media and Big Data Analytics,
              Multimodal and Sensors Data Analysis, Human Computer Interfaces, e-
              Health, Cultural, Media/Journalism and Security applications. He is the
              co-author of 222 papers in refereed journals, 69 book chapters, 10
              patents and 641 papers in international conferences. Dr. Kompatsiaris
              has participated (as PI and Project Coordinator) in numerous National
              and European research programs and direct collaborations with the
              industry. Currently, he is co-ordinating the “AI4Media: Artificial
              Intelligence for the Society and the Media Industry” NoE. He has been
              the co-organizer of various international conferences and workshops
              including the ACM International Conference on Multimedia Retrieval (ACM
              ICMR) in 2023 and has served as a regular reviewer, associate and guest
              editor for a number of journals and conferences, currently being an
              associate editor of IEEE Transactions on Image Processing. He is a
              member of the National Ethics and Technoethics Committee, the Scientific
              Advisory Board of the CHIST-ERA funding programme and has been an
              elected member of the IEEE Image, Video and Multidimensional Signal
              Processing - Technical Committee (IVMSP - TC). He is a Senior Member of
              IEEE and ACM. He is the co-founder of two spin-off companies: Infalia
              focusing on data intensive web services and applications and CDXi,
              creating AI and Multimodal Data Fusion solutions for Green and Digital
              Transformation.
            </p>
          </div>
        </div>
      </div>
    </div>
    <div class="banner" id="social">
      <div class="banner-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin-small">Social Events</h2>
          </div>
        </div>
      </div>
    </div>
    <div class="content">
      <div class="content-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column full-width">
            <p class="text">
              For MMM2024 we have an exciting social events programme spread out over three days.
              All locations are marked on the map:
            </p>
            <iframe class="image" src="https://www.google.com/maps/d/embed?mid=1WJsUXwAORjyXL-wdpdB39uUQj-u99q4&ehbc=2E312F&noprof=1" width="640" height="480"></iframe>
            <p class="text">
              On <b>Monday</b> there will be the <b>Welcome Reception</b> and in conjunction there will be the <a href="https://videobrowsershowdown.org/" target="_blank">Video Browser Showdown</a>!
            </p>
          </div>
        </div>
        <div class="flex-row-space-between">
          <div class="flex-item flex-column">
            <img class="image max-width-400" src="img/mokum-1.png">
          </div>
          <div class="flex-item flex-column">
            <img class="image max-width-400" src="img/mokum-2.png">
          </div>
        </div>
        <div class="flex-rows">
          <div class="flex-item flex-column">
            <p class="text">
              On <b>Tuesday</b> there will be a <b>boat trip of Amsterdam's canals</b> including busses to take you from the conference location to the departure point.
            </p>
            <p class="text">
              <img class="image image-wrap-text-custom max-width-283" src="img/thisisholland.jpg">
              On <b>Wednesday</b> there will be busses to take us to Amsterdam Noord as we will visit <a href="https://www.thisisholland.com/" target="_blank"><b>This is Holland!</b></a> where you can experience a spectacular 5D flight over many must-sees of the Netherlands!
              Fly like a bird and admire from the air the famous Amsterdam canals, the Wadden Sea, the Veluwe and more.
              Amazing special effects - such as wind, mist and smell - stimulate all the senses and make it seem as if you arereally
              flying through the clouds, crossing dikes and braving storms. Be surprised by the beauty of the Netherlands and the feeling of flying.
              <br>
              <br>
              Following the This is Holland! experience we will conclude the evening at <b><a href="https://tolhuistuin.nl/" target="_blank">Restaurant Tolhuistuin</a></b>, which offers a diverse menu accommodating various dietary preferences.
              <img class="image max-width-510" src="img/tht.jpg">
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
  <div class="footer-container"></div>
</body>

</html>