<!doctype html>
<html>

<head>
  <title>MMM2024</title>
  <meta charset="utf-8" name="viewport" content="width=device-width, initial-scale=1">
  <link href="https://use.fontawesome.com/releases/v5.2.0/css/all.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/frame.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/controls.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/custom.css" media="screen" rel="stylesheet" type="text/css" />
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Open+Sans+Condensed:300,700' rel='stylesheet' type='text/css'>
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700" rel="stylesheet">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script src="js/menu.js"></script>
  <script src="js/footer.js"></script>
  <style>
    .menu-conference {
      color: rgb(0, 0, 0) !important;
      opacity: 1 !important;
      font-weight: 700 !important;
    }
  </style>
</head>

<body>
  <div class="menu-container"></div>
  <div class="content-container">
    <div class="banner" style="background: url('img/feature.jpeg') no-repeat center; background-size: cover; height: 450px;">
      <div class="banner-table flex-column" style="background-color: rgba(0, 0, 0, 0.5);">
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h1 class="add-top-margin-small">Conference</h1>
          </div>
        </div>
      </div>
    </div>

    <div class="banner" id="program">
      <div class="banner-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin-small">Conference Program</h2>
          </div>
        </div>
      </div>
    </div>
    <div class="content">
      <div class="content-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column full-width">
            <h3>Preliminary Program Outline</h3>
            <hr>
            <p class="text">
              Below is a preliminary program outline.
              We are working on the program details and will update this page when it is ready.
            </p>
            <div class="scrollable-image-container center add-top-margin-small">
              <img class="scrollable-image center" src="img/mmm_2024_preliminary-program_outline.svg">
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="banner" id="keynotes">
      <div class="banner-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin-small">Keynotes</h2>
          </div>
        </div>
      </div>
    </div>
    <div class="content">
      <div class="content-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h3 id="keynote-vilanova">Keynote Anna Vilanova &#8212; Visual Analytics: Machine Learning and the Human in the Loop</h3>
            <hr>
            <p class="text">
              <img class="image image-wrap-text-custom max-width-200" src="img/anna.jpg">Visual Analytics wants to foster the strengths of humans and computers effectively through the combination of automatic data analysis methods, visualization, and interaction. Visual analytics is an extension of machine learning methods. It is also a complement to the already existing visualization techniques by the introduction of the concepts of reasoning and machine learning. Machine learning has
              successfully developed models that outperform humans in several tasks. However, this success is limited when it comes to increasing knowledge, and providing new understanding based on new data. Humans uniquely understand the world through intuition, common sense, creativity, and emotion, capabilities that are required for many multi-faceted tasks. In this talk, I will present our work and my view on embedding the human in the loop in the machine learning context through the
              concepts of visual analytics. In particular, we focus on data exploration, and hypothesis generation relying on dimensionality reduction methods as an effective visual analytics component for large high-dimensional data. Furthermore, I will discuss the promise, challenges, and current research in visual analytics to open the black box of machine learning models.
            </p>
            <p>
              <b>Prof. Dr. Anna Vilanova</b> is full professor in visual analytics (<a href="http://vis.win.tue.nl">vis.win.tue.nl</a>) since October 2019, at the department of Mathematics and Computer Science, at the Eindhoven University of Technology (TU/e). Previously she was associate professor for 6 years at the Computer Graphics & Visualization Group at EEMCS at the University of Delft, the Netherlands. From 2002 to August 2013, she was Assistant Professor at the Biomedical Image Analysis
              group of the Biomedical Engineering Department at TU/e. She is leading a research group in the subject of visual analytics and multivalued image analysis and visualization, focusing on visual analytics for high dimensional complex data and explainable AI. She focuses on Biomedical applications such as: Diffusion Weighted Imaging, 4D Flow and Pan-genomics. She was member of the steering committee of EuroVis (2014 -2018) and VCBM (2018-2022). She is elected member of the EUROGRAPHICS
              executive committee since 2015, vice president (2019-2022), and currently president of EUROGRAPHICS. She also became EUROGRAPHICS fellow in 2019. She is elected member of IEEE VIS Steering Committee (VSC) since 2021.
            </p>
          </div>
          <div class="flex-item flex-column">
            <h3 id="keynote-snoek">Keynote Cees Snoek &#8212; What Multimodal Foundation Models Cannot Perceive</h3>
            <hr>
            <p class="text">
              <img class="image image-wrap-text-custom max-width-200" src="img/cees.jpeg">
              Multimodal foundation models are a revolutionary class of AI models that provide impressive abilities to generate multimedia content and do so by interactive prompts in a seemingly creative manner.
              These foundation models are often self-supervised transformer-based models pre-trained on large volumes of data, typically collected from the web.
              They already form the basis of all state-of-the-art systems in computer vision and natural language processing across a wide range of tasks and have shown impressive transfer learning abilities.
              Despite their immense potential, these foundation models face challenges in fundamental perception tasks such as spatial grounding and temporal reasoning, have difficulty to operate on low-resource scenarios, and neglect human-alignment for ethical, legal, and societal acceptance.
              In this talk I will highlight recent work from my lab that identifies several of these challenges as well as ways to update foundation models to address these challenges and to do so in a sustainable way, without the need to retrain from scratch.
            </p>
            <p class="text">
              <b>Prof. Dr. Cees G.M. Snoek</b> is a full professor in computer science at the University of Amsterdam, where he heads the Video & Image Sense Lab. He is also a director of three public-private AI research labs: QUVA Lab with Qualcomm, Atlas Lab with TomTom and AIM Lab with the Inception Institute of Artificial Intelligence. At University spin-off Kepler Vision Technologies he acts as Chief Scientific Officer. Professor Snoek is also the director of the ELLIS Amsterdam Unit and
              scientific director of Amsterdam AI, a collaboration between government, academic, medical and other organisations in Amsterdam to help the city develop and deploy responsible AI.
              His research interests focus on making sense of video and images. He has published over 200 refereed book chapters, journal and conference papers, and frequently serves as an area chair of the major conferences in computer vision and multimedia. He is currently an associate editor for Computer Vision and Image Understanding and the IEEE Transactions on Pattern Analysis and Machine Intelligence.
            </p>
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>

  <div class="banner" id="social">
    <div class="banner-table flex-column">
      <div class="flex-row">
        <div class="flex-item flex-column">
          <h2 class="add-top-margin-small">Social Events</h2>
        </div>
      </div>
    </div>
  </div>
  <div class="content">
    <div class="content-table flex-column">
      <div class="flex-row">
        <div class="flex-item flex-column full-width">
          <p class="text">
            TBA.
          </p>
        </div>
      </div>
    </div>
  </div>

  <div class="footer-container"></div>
</body>

</html>